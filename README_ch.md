# 基于 YOLOv11 的纯视觉车辆测速方案

## 1. 前言

本项目实现了一套基于 **YOLOv11 目标检测 + 多目标跟踪 + 视觉几何补偿** 的车辆测速方案，面向无人机交通场景车辆测速。

与传统依赖雷达、地感线圈或严格相机标定的方案不同，本项目只依赖视频本身进行推理：  
**无需相机内外参、无需固定机位与固定航高，也不依赖飞行速度、航线规划等额外信息**。在无人机飞行姿态和高度**适度变化、画面相对稳定**的前提下，本方案可以给出车辆相对于地面的**近似绝对速度估计**，用于辅助分析与算法研究。


---

## 2. 项目简介与主要特点

本项目具有以下几个核心特点：

- **纯视觉测速，无需相机内外参**   
  - 无需相机内外参数、RTK 或 IMU，无需固定视角，姿态与飞行速度

- **输出近似“绝对速度”，而非简单画面位移**  
  通过对背景特征点进行匹配与单应性估计，对无人机自身的平移/轻微姿态变化进行补偿；  
  补偿后剩余的位移视为车辆相对于地面的运动，并转换为 km/h。  
  在假定地面近似平面、无人机运动较平稳的前提下，可视为车辆的**近似绝对速度**。

- 🎯 **测速误差与检测/跟踪/状态判定强相关**  
  - YOLOv11 的检测质量影响框位置稳定性；  
  - 跟踪算法（如 BoT-SORT）的 ID 一致性决定轨迹是否连续；  
  - “运动目标”的判定逻辑直接影响速度显示与误差（静止车辆若被判为运动，就可能出现 1–3 km/h 的虚假小速度）。  
  本项目强调：这是一个**完整流水线**，检测、跟踪与静止/运动判定的任何抖动，都会传导到最终测速结果中。

- ⚙️ **高度可配置的 `config.yaml`**  
  项目中绝大多数关键参数都集中在配置文件中，包括：  
  - 像素到米的比例（pixel_to_meter）；  
  - 每 N 帧估计一次的帧间隔（frame_stride）；  
  - 判定“运动”的最小位移与最小速度（min_disp_pixels / min_moving_kmh）；  
  - 时间窗口长度（window_sec）；  
  - 可视化颜色、文本显示开关等。  
  用户可以根据自己无人机高度、分辨率与业务误差容忍度，通过修改配置快速适配不同场景，无需大幅改动代码。